{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor\n",
    "from torch import nn as nn\n",
    "from torch import optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchmetrics import Accuracy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##MANIPULATING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/air_quality_health_impact_data.csv')\n",
    "data.isnull().sum()\n",
    "# no null values\n",
    "features = data.drop('HealthImpactClass', axis=1)\n",
    "label = data['HealthImpactClass'].astype(int)\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(scaled_features, label, test_size=0.2, random_state= 42)\n",
    "X_train = tensor(X_train, dtype=torch.float32)\n",
    "X_test = tensor(X_test, dtype=torch.float32)\n",
    "Y_train = tensor(Y_train.to_numpy(), dtype=torch.long)\n",
    "Y_test = tensor(Y_test.to_numpy(), dtype=torch.long)\n",
    "\n",
    "training_set = TensorDataset(X_train, Y_train)\n",
    "testing_set = TensorDataset(X_test,Y_test)\n",
    "\n",
    "training_loader = DataLoader(training_set, batch_size=32, shuffle=True)\n",
    "testing_loader = DataLoader(testing_set, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##BUILDING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiModel, self).__init__()\n",
    "        self.ly1 = nn.Linear(14, 28)\n",
    "        self.dp1 = nn.Dropout(0.5)\n",
    "        self.ly2 = nn.Linear(28, 18)\n",
    "        self.dp2 = nn.Dropout(0.5)\n",
    "        self.ly3 = nn.Linear(18, 12)\n",
    "        self.dp3 = nn.Dropout(0.5)\n",
    "        self.ly4 = nn.Linear(12,6)\n",
    "        self.dp4 = nn.Dropout(0.5)\n",
    "        self.ly5 = nn.Linear(6,5)\n",
    "        self.act = nn.Softmax(dim = 1)\n",
    "    def forward(self, x):\n",
    "        x = self.dp1(F.relu(self.ly1(x)))\n",
    "        x = self.dp2(F.leaky_relu(self.ly2(x)))\n",
    "        x = self.dp3(F.leaky_relu(self.ly3(x)))\n",
    "        x = self.dp4(F.leaky_relu(self.ly4(x)))\n",
    "        x = self.act(self.ly5(x))\n",
    "        return x\n",
    "model = MultiModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##TRAINING TOOLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##EARLY STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta = .01):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.stop = False\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > (self.best_loss - self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter > self.patience:\n",
    "                self.stop = True\n",
    "        else:\n",
    "            self.counter = 0\n",
    "            self.best_loss = val_loss\n",
    "early_stop = EarlyStopping(15, 0.0001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Loss: 1.1272964812304875 | Epoch: 0\n",
      "Running Loss: 1.0210820844728652 | Epoch: 20\n",
      "Early Stop 27 | 1.0142976915514148\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0\n",
    "    model.train()\n",
    "    for features, label in training_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(features)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    val_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for features, label in testing_loader:\n",
    "            output = model(features)\n",
    "            loss = criterion(output, label)\n",
    "            val_loss += loss.item()\n",
    "    early_stop(val_loss/len(testing_loader))\n",
    "    if early_stop.stop:\n",
    "        print(f\"Early Stop {epoch} | {val_loss/len(testing_loader)}\")\n",
    "        break\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Running Loss: {running_loss/len(training_loader)} | Epoch: {epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##EVALUATION LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8899397850036621\n"
     ]
    }
   ],
   "source": [
    "accuracy = Accuracy(task='multiclass', num_classes=5)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  for features, labels in testing_loader:\n",
    "    output = model(features)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    accuracy.update(predicted, labels)\n",
    "\n",
    "print(f'Accuracy: {accuracy.compute().item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn_multi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
